{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "from PIL import Image\n",
    "import os\n",
    "import IPython.display as display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bytestring_feature(list_of_bytestrings):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=list_of_bytestrings))\n",
    "\n",
    "def _int_feature(list_of_ints): # int64\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=list_of_ints))\n",
    "\n",
    "def _float_feature(list_of_floats): # float32\n",
    "    return tf.train.Feature(float_list=tf.train.FloatList(value=list_of_floats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train - 67.5%\n",
    "# Val - 22.5%\n",
    "# Test - 10%\n",
    "\n",
    "df = pd.read_csv('data/df.csv')\n",
    "train_data = pd.read_csv('data/train.csv')\n",
    "test_data = pd.read_csv('data/test.csv')\n",
    "val_data = pd.read_csv('data/val.csv')\n",
    "\n",
    "label_encoder = LabelEncoder().fit(df.make_id.astype(str))\n",
    "train_data.make_id = label_encoder.transform(train_data.make_id.astype(str))\n",
    "label_encoder = LabelEncoder().fit(df.model_id.astype(str))\n",
    "train_data.model_id = label_encoder.transform(train_data.model_id.astype(str))\n",
    "\n",
    "label_encoder = LabelEncoder().fit(df.make_id.astype(str))\n",
    "val_data.make_id = label_encoder.transform(val_data.make_id.astype(str))\n",
    "label_encoder = LabelEncoder().fit(df.model_id.astype(str))\n",
    "val_data.model_id = label_encoder.transform(val_data.model_id.astype(str))\n",
    "\n",
    "label_encoder = LabelEncoder().fit(df.make_id.astype(str))\n",
    "test_data.make_id = label_encoder.transform(test_data.make_id.astype(str))\n",
    "label_encoder = LabelEncoder().fit(df.model_id.astype(str))\n",
    "test_data.model_id = label_encoder.transform(test_data.model_id.astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QtbF-_ZaTxIe"
   },
   "outputs": [],
   "source": [
    "train_image_paths = train_data['filename']\n",
    "train_labels = train_data[['make_id', 'model_id']]\n",
    "\n",
    "val_image_paths = val_data['filename']\n",
    "val_labels = val_data[['make_id', 'model_id']]\n",
    "\n",
    "test_image_paths = test_data['filename']\n",
    "test_labels = test_data[['make_id', 'model_id']]\n",
    "\n",
    "tfrecord_train_dir = 'tfrecords/train/'\n",
    "tfrecord_val_dir = 'tfrecords/val/'\n",
    "tfrecord_test_dir = 'tfrecords/test/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAIN DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pattern matches 92201 images which will be rewritten as 128 .tfrec files containing 721 images each.\n"
     ]
    }
   ],
   "source": [
    "SHARDS = 128\n",
    "nb_images = len(train_data)\n",
    "shard_size = math.ceil(1.0 * nb_images / SHARDS)\n",
    "print(\"Pattern matches {} images which will be rewritten as {} .tfrec files containing {} images each.\".format(nb_images, SHARDS, shard_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _parse_function(filename, label):\n",
    "    img_raw = tf.io.read_file(filename)\n",
    "    return img_raw, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = tf.data.Dataset.from_tensor_slices((train_image_paths, train_labels))\n",
    "dataset = files.map(_parse_function)\n",
    "dataset = dataset.batch(shard_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aXjI7hV2UnaB"
   },
   "outputs": [],
   "source": [
    "def to_tfrecord(tfrec_filewriter, img_bytes, label):\n",
    "    one_hot_class = [np.eye(163)[label[0]], np.eye(1716)[label[1]]]\n",
    "    \n",
    "    feature = {\n",
    "        \"image\": _bytestring_feature([img_bytes]), # one image in the list\n",
    "        \"make_id\": _int_feature([label[0]]),\n",
    "        \"make_id_oh\": _float_feature(one_hot_class[0].tolist()),\n",
    "        \"model_id\": _int_feature([label[1]]),\n",
    "        \"model_id_oh\": _float_feature(one_hot_class[1].tolist())\n",
    "    }\n",
    "    return tf.train.Example(features=tf.train.Features(feature=feature))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Writing TFRecords\")\n",
    "for shard, (image, label) in enumerate(dataset):\n",
    "  # batch size used as shard size here\n",
    "  shard_size = image.numpy().shape[0]\n",
    "  # good practice to have the number of records in the filename\n",
    "  filename = tfrecord_train_dir + \"{:02d}-{}.tfrec\".format(shard, shard_size)\n",
    "  \n",
    "  with tf.io.TFRecordWriter(filename) as out_file:\n",
    "    for i in range(shard_size):\n",
    "        example = to_tfrecord(out_file,\n",
    "                              image.numpy()[i],\n",
    "                              label.numpy()[i])\n",
    "        out_file.write(example.SerializeToString())\n",
    "    \n",
    "    print(\"Wrote file {} containing {} records\".format(filename, shard_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VALIDATION DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pattern matches 30734 images which will be rewritten as 32 .tfrec files containing 961 images each.\n"
     ]
    }
   ],
   "source": [
    "SHARDS = 32\n",
    "nb_images = len(val_data)\n",
    "shard_size = math.ceil(1.0 * nb_images / SHARDS)\n",
    "print(\"Pattern matches {} images which will be rewritten as {} .tfrec files containing {} images each.\".format(nb_images, SHARDS, shard_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = tf.data.Dataset.from_tensor_slices((val_image_paths, val_labels))\n",
    "dataset = files.map(_parse_function)\n",
    "dataset = dataset.batch(shard_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing TFRecords\n",
      "Wrote file tfrecords/val/00-961.tfrec containing 961 records\n",
      "Wrote file tfrecords/val/01-961.tfrec containing 961 records\n",
      "Wrote file tfrecords/val/02-961.tfrec containing 961 records\n",
      "Wrote file tfrecords/val/03-961.tfrec containing 961 records\n",
      "Wrote file tfrecords/val/04-961.tfrec containing 961 records\n",
      "Wrote file tfrecords/val/05-961.tfrec containing 961 records\n",
      "Wrote file tfrecords/val/06-961.tfrec containing 961 records\n",
      "Wrote file tfrecords/val/07-961.tfrec containing 961 records\n",
      "Wrote file tfrecords/val/08-961.tfrec containing 961 records\n",
      "Wrote file tfrecords/val/09-961.tfrec containing 961 records\n",
      "Wrote file tfrecords/val/10-961.tfrec containing 961 records\n",
      "Wrote file tfrecords/val/11-961.tfrec containing 961 records\n",
      "Wrote file tfrecords/val/12-961.tfrec containing 961 records\n",
      "Wrote file tfrecords/val/13-961.tfrec containing 961 records\n",
      "Wrote file tfrecords/val/14-961.tfrec containing 961 records\n",
      "Wrote file tfrecords/val/15-961.tfrec containing 961 records\n",
      "Wrote file tfrecords/val/16-961.tfrec containing 961 records\n",
      "Wrote file tfrecords/val/17-961.tfrec containing 961 records\n",
      "Wrote file tfrecords/val/18-961.tfrec containing 961 records\n",
      "Wrote file tfrecords/val/19-961.tfrec containing 961 records\n",
      "Wrote file tfrecords/val/20-961.tfrec containing 961 records\n",
      "Wrote file tfrecords/val/21-961.tfrec containing 961 records\n",
      "Wrote file tfrecords/val/22-961.tfrec containing 961 records\n",
      "Wrote file tfrecords/val/23-961.tfrec containing 961 records\n",
      "Wrote file tfrecords/val/24-961.tfrec containing 961 records\n",
      "Wrote file tfrecords/val/25-961.tfrec containing 961 records\n",
      "Wrote file tfrecords/val/26-961.tfrec containing 961 records\n",
      "Wrote file tfrecords/val/27-961.tfrec containing 961 records\n",
      "Wrote file tfrecords/val/28-961.tfrec containing 961 records\n",
      "Wrote file tfrecords/val/29-961.tfrec containing 961 records\n",
      "Wrote file tfrecords/val/30-961.tfrec containing 961 records\n",
      "Wrote file tfrecords/val/31-943.tfrec containing 943 records\n"
     ]
    }
   ],
   "source": [
    "print(\"Writing TFRecords\")\n",
    "for shard, (image, label) in enumerate(dataset):\n",
    "  # batch size used as shard size here\n",
    "  shard_size = image.numpy().shape[0]\n",
    "  # good practice to have the number of records in the filename\n",
    "  filename = tfrecord_val_dir + \"{:02d}-{}.tfrec\".format(shard, shard_size)\n",
    "  \n",
    "  with tf.io.TFRecordWriter(filename) as out_file:\n",
    "    for i in range(shard_size):\n",
    "        example = to_tfrecord(out_file,\n",
    "                              image.numpy()[i],\n",
    "                              label.numpy()[i])\n",
    "        out_file.write(example.SerializeToString())\n",
    "    \n",
    "    print(\"Wrote file {} containing {} records\".format(filename, shard_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pattern matches 13791 images which will be rewritten as 16 .tfrec files containing 862 images each.\n"
     ]
    }
   ],
   "source": [
    "SHARDS = 16\n",
    "nb_images = len(test_data)\n",
    "shard_size = math.ceil(1.0 * nb_images / SHARDS)\n",
    "print(\"Pattern matches {} images which will be rewritten as {} .tfrec files containing {} images each.\".format(nb_images, SHARDS, shard_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = tf.data.Dataset.from_tensor_slices((test_image_paths, test_labels))\n",
    "dataset = files.map(_parse_function)\n",
    "dataset = dataset.batch(shard_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing TFRecords\n",
      "Wrote file tfrecords/test/00-862.tfrec containing 862 records\n",
      "Wrote file tfrecords/test/01-862.tfrec containing 862 records\n",
      "Wrote file tfrecords/test/02-862.tfrec containing 862 records\n",
      "Wrote file tfrecords/test/03-862.tfrec containing 862 records\n",
      "Wrote file tfrecords/test/04-862.tfrec containing 862 records\n",
      "Wrote file tfrecords/test/05-862.tfrec containing 862 records\n",
      "Wrote file tfrecords/test/06-862.tfrec containing 862 records\n",
      "Wrote file tfrecords/test/07-862.tfrec containing 862 records\n",
      "Wrote file tfrecords/test/08-862.tfrec containing 862 records\n",
      "Wrote file tfrecords/test/09-862.tfrec containing 862 records\n",
      "Wrote file tfrecords/test/10-862.tfrec containing 862 records\n",
      "Wrote file tfrecords/test/11-862.tfrec containing 862 records\n",
      "Wrote file tfrecords/test/12-862.tfrec containing 862 records\n",
      "Wrote file tfrecords/test/13-862.tfrec containing 862 records\n",
      "Wrote file tfrecords/test/14-862.tfrec containing 862 records\n",
      "Wrote file tfrecords/test/15-861.tfrec containing 861 records\n"
     ]
    }
   ],
   "source": [
    "print(\"Writing TFRecords\")\n",
    "for shard, (image, label) in enumerate(dataset):\n",
    "  # batch size used as shard size here\n",
    "  shard_size = image.numpy().shape[0]\n",
    "  # good practice to have the number of records in the filename\n",
    "  filename = tfrecord_test_dir + \"{:02d}-{}.tfrec\".format(shard, shard_size)\n",
    "  \n",
    "  with tf.io.TFRecordWriter(filename) as out_file:\n",
    "    for i in range(shard_size):\n",
    "        example = to_tfrecord(out_file,\n",
    "                              image.numpy()[i],\n",
    "                              label.numpy()[i])\n",
    "        out_file.write(example.SerializeToString())\n",
    "    \n",
    "    print(\"Wrote file {} containing {} records\".format(filename, shard_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## READ TRAIN/VAL TFRECORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = [224,224]\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "def read_tfrecord(example):\n",
    "    features = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string),  # tf.string = bytestring (not text string)\n",
    "        \"make_id\": tf.io.FixedLenFeature([], tf.int64),   # shape [] means scalar\n",
    "        \"make_id_oh\": tf.io.VarLenFeature(tf.float32) # a certain number of floats\n",
    "        \"model_id\": tf.io.FixedLenFeature([], tf.int64),   # shape [] means scalar\n",
    "        \"model_id_oh\": tf.io.VarLenFeature(tf.float32)# a certain number of floats\n",
    "    }\n",
    "    \n",
    "    feature = tf.io.parse_single_example(example, features)\n",
    "    image = tf.image.decode_jpeg(feature['image'], channels=3)\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    image = tf.image.resize(image, [*IMAGE_SIZE])\n",
    "    label = feature['class']\n",
    "    one_hot_class = tf.sparse.to_dense(feature['one_hot_class'])\n",
    "    one_hot_class = tf.reshape(one_hot_class, [42])\n",
    "    return image, one_hot_class\n",
    "\n",
    "\n",
    "option_no_order = tf.data.Options()\n",
    "option_no_order.experimental_deterministic = False\n",
    "\n",
    "train_path = tf.io.gfile.glob(tfrecord_train_dir+ \"*.tfrec\")\n",
    "val_path = tf.io.gfile.glob(tfrecord_val_dir + \"*.tfrec\")\n",
    "\n",
    "training_dataset = tf.data.TFRecordDataset(train_path, num_parallel_reads=AUTO)\n",
    "training_dataset = training_dataset.with_options(option_no_order)\n",
    "training_dataset = training_dataset.map(read_tfrecord, num_parallel_calls=AUTO)\n",
    "training_dataset = training_dataset.batch(BATCH_SIZE)\n",
    "\n",
    "val_dataset = tf.data.TFRecordDataset(val_path, num_parallel_reads=AUTO)\n",
    "val_dataset = val_dataset.with_options(option_no_order)\n",
    "val_dataset = val_dataset.map(read_tfrecord, num_parallel_calls=AUTO)\n",
    "val_dataset = val_dataset.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 224, 224, 3) (128, 42)\n"
     ]
    }
   ],
   "source": [
    "for image, label in training_dataset.take(1):\n",
    "    print(image.numpy().shape, label.numpy().shape)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 224, 224, 3) (128, 42)\n"
     ]
    }
   ],
   "source": [
    "for image, label in val_dataset.take(1):\n",
    "    print(image.numpy().shape, label.numpy().shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# READ TEST TFRECORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = [224,224]\n",
    "BATCH_SIZE = 128\n",
    "\n",
    "def read_tfrecord(example):\n",
    "    features = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string),  # tf.string = bytestring (not text string)\n",
    "    }\n",
    "    \n",
    "    feature = tf.io.parse_single_example(example, features)\n",
    "    image = tf.image.decode_jpeg(feature['image'], channels=3)\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    image = tf.image.resize(image, [*IMAGE_SIZE])\n",
    "    return image\n",
    "\n",
    "    \n",
    "# read from TFRecords. For optimal performance, read from multiple\n",
    "# TFRecord files at once and set the option experimental_deterministic = False\n",
    "# to allow order-altering optimizations.\n",
    "\n",
    "option_no_order = tf.data.Options()\n",
    "option_no_order.experimental_deterministic = False\n",
    "\n",
    "test_path = tf.io.gfile.glob(tfrecord_test_dir+ \"*.tfrec\")\n",
    "\n",
    "test_dataset = tf.data.TFRecordDataset(test_path, num_parallel_reads=AUTO)\n",
    "test_dataset = test_dataset.with_options(option_no_order)\n",
    "test_dataset = test_dataset.map(read_tfrecord, num_parallel_calls=AUTO)\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image in test_dataset.take(1):\n",
    "    print(image.numpy().shape)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "TFrecords and tf.train.Example.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
